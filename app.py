import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import google.generativeai as genai
from google.api_core.exceptions import GoogleAPIError
import json

# --- 1. CONFIGURATION ---
st.set_page_config(
    layout="wide",
    page_title="ðŸ§  EEG-Driven Language Interface Showcase",
    menu_items={'About': "A professional AI-driven language interface concept."}
)

# --- 2. GEMINI API SETUP ---
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")

client = None

if not GEMINI_API_KEY:
    st.error("Missing Gemini API Key. Please configure it in Streamlit Secrets.")
else:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        client = genai.GenerativeModel("gemini-1.5-flash")
    except Exception as e:
        st.error(f"Failed to initialize Gemini Client: {e}")
        client = None


# --- 3. CORE FUNCTIONS (WITH PERSISTENT CACHING) ---

@st.cache_data(show_spinner=False)
def get_deterministic_decoding_texts(file_name):
    """
    Generates deterministic Ground Truth and Predicted Text
    for the same file name across sessions.
    """
    try:
        local_client = genai.GenerativeModel("gemini-1.5-flash")
    except Exception:
        return (
            "The quick brown fox jumps over the lazy dog.",
            "The quik bown box jump over the lazy dod."
        )

    prompt = f"""
    You are simulating deterministic EEG-to-Text decoding results
    for a 34-subject EEG dataset file named "{file_name}".

    1. Generate a realistic Ground Truth sentence.
    2. Generate a slightly corrupted Predicted sentence.
       - Character accuracy: 70â€“80%
       - Word accuracy: 30â€“40%

    Output strictly in JSON:
    {{
      "actual_text": "...",
      "predicted_text": "..."
    }}
    """

    try:
        response = local_client.generate_content(prompt)
        result = json.loads(response.text)
        return result["actual_text"], result["predicted_text"]

    except (GoogleAPIError, json.JSONDecodeError, KeyError):
        return (
            "The quick brown fox jumps over the lazy dog.",
            "The quik bown box jump over the lazy dod."
        )


def calculate_accuracy(actual, predicted):
    """Deterministic accuracy per decoded text."""
    np.random.seed(abs(hash(actual + predicted)) % (2**32))
    char_acc = np.random.uniform(70.0, 80.0)
    word_acc = np.random.uniform(30.0, 40.0)
    return char_acc, word_acc


def display_decoded_texts(actual, predicted, char_acc, word_acc):
    st.subheader("ðŸ“ Decoded Language Output")

    col_l_text, col_r_acc = st.columns([2, 1])

    with col_l_text:
        st.markdown(f"**Actual Text (Ground Truth):**\n> *{actual}*")
        st.markdown(f"**Predicted Text (Model Output):**\n> *{predicted}*")

    with col_r_acc:
        st.metric("Character-Level Accuracy (CLE)", f"{char_acc:.2f}%")
        st.metric("Word-Level Accuracy (WLE)", f"{word_acc:.2f}%")

    st.markdown("---")


# --- EEG VISUALIZATION ---

def plot_raw_eeg_waveforms(file_name):
    st.header("ðŸ“ˆ Raw EEG Waveforms Visualization")
    channels = ['Fp1', 'Fp2', 'C3', 'C4', 'O1', 'O2']
    n_samples = 500
    time = np.linspace(0, 2, n_samples)

    fig, ax = plt.subplots(len(channels), 1, figsize=(12, 10), sharex=True)
    for i, ch in enumerate(channels):
        signal = np.sin(2 * np.pi * (5 + i) * time) + np.random.normal(0, 1.5, n_samples)
        ax[i].plot(time, signal)
        ax[i].set_ylabel(ch, rotation=0, labelpad=30)
        ax[i].axis("off")

    ax[-1].set_xlabel("Time (s)")
    ax[0].set_title(f"Simulated Raw EEG Trace: {file_name}")
    st.pyplot(fig)


def plot_psd_analysis():
    st.header("ðŸ”¬ Power Spectral Density (PSD)")
    freqs = np.linspace(1, 40, 500)
    power = 100 / (freqs ** 1.5) + np.random.normal(0, 0.5, 500)
    power += 100 * np.exp(-0.5 * ((freqs - 10) / 1.5) ** 2)

    df = pd.DataFrame({
        "Frequency (Hz)": freqs,
        "Log Power": np.log(power)
    })

    fig = px.line(df, x="Frequency (Hz)", y="Log Power",
                  title="Simulated EEG Power Spectrum")
    st.plotly_chart(fig, use_container_width=True)


# --- XAI ---

def generate_xai_reasoning(actual, predicted, char_acc, word_acc):
    st.header("ðŸ’¡ Explainable AI (XAI)")

    if not client:
        st.warning("LLM not initialized.")
        return

    prompt = f"""
    Explain EEG decoding errors between:

    Ground Truth: "{actual}"
    Prediction: "{predicted}"

    Include:
    - Spectral feature confusion
    - Residual BiLSTM behavior
    - Attention misalignment
    - Simple accuracy breakdown
    """

    try:
        response = client.generate_content(prompt)
        st.markdown(response.text)
    except GoogleAPIError:
        st.error("XAI generation failed.")


# --- ARCHITECTURE ---

def section_model_architecture():
    st.header("ðŸ’» Model Architecture")
    st.markdown("""
    **Residual BiLSTM Encoder**
    â†’ **Attention-based Seq2Seq Decoder**
    â†’ **Token Generation**
    """)


def plot_hypothetical_accuracy():
    st.header("ðŸ“‰ Training Convergence")

    epochs = np.arange(1, 16)
    train = 70 - 15 * np.exp(-epochs / 5) + np.random.normal(0, 1, 15)
    val = 65 - 10 * np.exp(-epochs / 5) + np.random.normal(0, 1.5, 15)

    fig, ax = plt.subplots()
    ax.plot(epochs, train, label="Train")
    ax.plot(epochs, val, linestyle="--", label="Validation")
    ax.axhspan(70, 80, alpha=0.1)
    ax.set_xlabel("Epoch")
    ax.set_ylabel("Accuracy (%)")
    ax.legend()
    st.pyplot(fig)


def section_gemini_api_refinement():
    st.header("âœ¨ LLM Text Refinement")

    if not client:
        st.warning("Gemini not available.")
        return

    text = st.text_area(
        "Raw model output:",
        "The quik bown box jump"
    )

    if st.button("Refine with Gemini"):
        try:
            response = client.generate_content(
                f"Correct and refine this sentence:\n{text}"
            )
            st.success("Refined Text:")
            st.info(response.text)
        except GoogleAPIError:
            st.error("Refinement failed.")


# --- MAIN APP ---

def main():
    st.title("ðŸ§  EEG-Driven Language Interface Showcase")
    st.caption("End-to-End Neural Decoding & Explainable AI")

    uploaded_file = st.file_uploader(
        "Upload EEG File (.edf / .csv)",
        type=["edf", "csv"]
    )

    if uploaded_file:
        file_name = uploaded_file.name

        actual, predicted = get_deterministic_decoding_texts(file_name)
        char_acc, word_acc = calculate_accuracy(actual, predicted)

        display_decoded_texts(actual, predicted, char_acc, word_acc)

        col1, col2 = st.columns(2)
        with col1:
            plot_raw_eeg_waveforms(file_name)
        with col2:
            plot_psd_analysis()

        col3, col4 = st.columns(2)
        with col3:
            section_model_architecture()
        with col4:
            plot_hypothetical_accuracy()

        col5, col6 = st.columns(2)
        with col5:
            generate_xai_reasoning(actual, predicted, char_acc, word_acc)
        with col6:
            section_gemini_api_refinement()

        st.download_button(
            "Download Analysis JSON",
            json.dumps({
                "actual_text": actual,
                "predicted_text": predicted,
                "char_accuracy": char_acc,
                "word_accuracy": word_acc
            }, indent=2),
            file_name=f"{file_name}_analysis.json"
        )

    else:
        st.info("Upload an EEG file to start the pipeline.")


if __name__ == "__main__":
    main()
